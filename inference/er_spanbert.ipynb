{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:12.824672Z",
     "start_time": "2025-12-04T09:10:12.821226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "project_cache_dir = \"./hf_cache\"\n",
    "os.makedirs(project_cache_dir, exist_ok=True)"
   ],
   "id": "eca132b6d2442cf1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "13bf3b578d32298b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:16.258253Z",
     "start_time": "2025-12-04T09:10:12.858972Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# models\n",
    "model_name = \"SpanBERT/spanbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=project_cache_dir,\n",
    "    lcoal_files_only=False\n",
    ")\n",
    "encoder = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=project_cache_dir,\n",
    "    local_files_only=False\n",
    ")\n",
    "encoder.eval()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:17.303460Z",
     "start_time": "2025-12-04T09:10:16.848544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "print(\"[Stage 1] Loaded SpanBERT-base model on device:\", device)"
   ],
   "id": "2f93166f492a34b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 1] Loaded SpanBERT-base model on device: cuda\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:17.428973Z",
     "start_time": "2025-12-04T09:10:17.425953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test input\n",
    "text = (\"Lionel Messi scored a brilliant goal. \"\n",
    "        \"The Argentine forward celebrated with his teammates. \"\n",
    "        \"He is considered one of the best players in the world.\")\n",
    "print(\"[Stage 2] Input text:\\n\", text)"
   ],
   "id": "b68a93be62d0e47a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 2] Input text:\n",
      " Lionel Messi scored a brilliant goal. The Argentine forward celebrated with his teammates. He is considered one of the best players in the world.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:17.567592Z",
     "start_time": "2025-12-04T09:10:17.549344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inference\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = {k:v.to(device) for k,v in tokens.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = encoder(**tokens)\n",
    "\n",
    "token_embeddings = outputs.last_hidden_state.squeeze(0)  # [seq_len, hidden_size]\n",
    "print(\"\\n[Stage 3] Token embeddings shape:\", token_embeddings.shape)"
   ],
   "id": "98f84311df3c879c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 3] Token embeddings shape: torch.Size([33, 768])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:17.684629Z",
     "start_time": "2025-12-04T09:10:17.681462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_span_width = 2\n",
    "span_indices = []\n",
    "for i in range(token_embeddings.size(0)):\n",
    "    for w in range(1, max_span_width+1):\n",
    "        if i + w <= token_embeddings.size(0):\n",
    "            span_indices.append((i, i + w - 1))\n",
    "print(\"\\n[Stage 4] Candidate spans (token indices):\\n\", span_indices)"
   ],
   "id": "89168abba651d66d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 4] Candidate spans (token indices):\n",
      " [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 8), (8, 8), (8, 9), (9, 9), (9, 10), (10, 10), (10, 11), (11, 11), (11, 12), (12, 12), (12, 13), (13, 13), (13, 14), (14, 14), (14, 15), (15, 15), (15, 16), (16, 16), (16, 17), (17, 17), (17, 18), (18, 18), (18, 19), (19, 19), (19, 20), (20, 20), (20, 21), (21, 21), (21, 22), (22, 22), (22, 23), (23, 23), (23, 24), (24, 24), (24, 25), (25, 25), (25, 26), (26, 26), (26, 27), (27, 27), (27, 28), (28, 28), (28, 29), (29, 29), (29, 30), (30, 30), (30, 31), (31, 31), (31, 32), (32, 32)]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:17.791833Z",
     "start_time": "2025-12-04T09:10:17.786245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "span_embeddings = torch.stack([token_embeddings[start] + token_embeddings[end] for start, end in span_indices])\n",
    "print(\"\\n[Stage 5] Span embeddings shape:\", span_embeddings.shape)"
   ],
   "id": "5971c974e31f64ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 5] Span embeddings shape: torch.Size([65, 768])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:17.903360Z",
     "start_time": "2025-12-04T09:10:17.899414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores = torch.matmul(span_embeddings, span_embeddings.T)\n",
    "scores = torch.tril(scores, diagonal=-1)\n",
    "print(\"\\n[Stage 6] Antecedent scores matrix shape:\", scores.shape)"
   ],
   "id": "a3d4205602384d05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 6] Antecedent scores matrix shape: torch.Size([65, 65])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:18.029462Z",
     "start_time": "2025-12-04T09:10:18.008705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clustering \n",
    "clusters = []\n",
    "span_to_cluster = {}\n",
    "for i, (start, end) in enumerate(span_indices):\n",
    "    if i == 0:\n",
    "        span_to_cluster[i] = len(clusters)\n",
    "        clusters.append([(start, end)])\n",
    "        continue\n",
    "    antecedents = scores[i,:i]\n",
    "    if antecedents.max() > .2:\n",
    "        best = antecedents.argmax().item()\n",
    "        span_to_cluster[i] = span_to_cluster[best]\n",
    "        clusters[span_to_cluster[i]].append((start, end))\n",
    "    else:\n",
    "        span_to_cluster[i] = len(clusters)\n",
    "        clusters.append([(start, end)])\n",
    "        \n",
    "print(\"\\n[Stage 7] Clusters (token indices):\\n\", clusters)"
   ],
   "id": "435f5a809f2dd894",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 7] Clusters (token indices):\n",
      " [[(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 8), (8, 8), (8, 9), (9, 9), (9, 10), (10, 10), (10, 11), (11, 11), (11, 12), (12, 12), (12, 13), (13, 13), (13, 14), (14, 14), (14, 15), (15, 15), (15, 16), (16, 16), (16, 17), (17, 17), (17, 18), (18, 18), (18, 19), (19, 19), (19, 20), (20, 20), (20, 21), (21, 21), (21, 22), (22, 22), (22, 23), (23, 23), (23, 24), (24, 24), (24, 25), (25, 25), (25, 26), (26, 26), (26, 27), (27, 27), (27, 28), (28, 28), (28, 29), (29, 29), (29, 30), (30, 30), (30, 31), (31, 31), (31, 32), (32, 32)]]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:18.140433Z",
     "start_time": "2025-12-04T09:10:18.135594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# conversion back to text\n",
    "token_list = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"].squeeze())\n",
    "clusters_text = []\n",
    "for cluster in clusters:\n",
    "    clusters_text.append([\" \".join(token_list[start:end+1]) for start, end in cluster])\n"
   ],
   "id": "254c152d04f7d3c2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:18.266532Z",
     "start_time": "2025-12-04T09:10:18.262946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# output\n",
    "print(\"Candidate clusters (resolved mentions):\")\n",
    "for c in clusters_text:\n",
    "    print(c)\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate clusters (resolved mentions):\n",
      "['[CLS]', '[CLS] lion', 'lion', 'lion ##el', '##el', '##el mess', 'mess', 'mess ##i', '##i', '##i scored', 'scored', 'scored a', 'a', 'a brilliant', 'brilliant', 'brilliant goal', 'goal', 'goal .', '.', '. the', 'the', 'the a', 'a', 'a ##rgent', '##rgent', '##rgent ##ine', '##ine', '##ine forward', 'forward', 'forward celebrated', 'celebrated', 'celebrated with', 'with', 'with his', 'his', 'his teammates', 'teammates', 'teammates .', '.', '. he', 'he', 'he is', 'is', 'is considered', 'considered', 'considered one', 'one', 'one of', 'of', 'of the', 'the', 'the best', 'best', 'best players', 'players', 'players in', 'in', 'in the', 'the', 'the world', 'world', 'world .', '.', '. [SEP]', '[SEP]']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:18.391138Z",
     "start_time": "2025-12-04T09:10:18.372541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, (start, end) in enumerate(span_indices):\n",
    "    span_text = \" \".join(token_list[start:end+1])\n",
    "    if i == 0:\n",
    "        print(f\"{span_text:20} -> None\")\n",
    "        continue\n",
    "    antecedents = scores[i,:i]\n",
    "    top_score, top_idx = antecedents.max(0)\n",
    "    top_span = \" \".join(token_list[span_indices[top_idx][0]:span_indices[top_idx][1]+1])\n",
    "    print(f\"{span_text:20} -> {top_span:20} (score={top_score.item():.2f})\")"
   ],
   "id": "843c07557ba8a6db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]                -> None\n",
      "[CLS] lion           -> [CLS]                (score=48.06)\n",
      "lion                 -> [CLS] lion           (score=50.67)\n",
      "lion ##el            -> lion                 (score=53.70)\n",
      "##el                 -> lion ##el            (score=72.69)\n",
      "##el mess            -> ##el                 (score=80.84)\n",
      "mess                 -> ##el mess            (score=60.57)\n",
      "mess ##i             -> ##el                 (score=61.99)\n",
      "##i                  -> ##el                 (score=70.94)\n",
      "##i scored           -> ##i                  (score=80.64)\n",
      "scored               -> ##i scored           (score=90.88)\n",
      "scored a             -> scored               (score=99.10)\n",
      "a                    -> scored a             (score=107.03)\n",
      "a brilliant          -> a                    (score=99.97)\n",
      "brilliant            -> a brilliant          (score=87.02)\n",
      "brilliant goal       -> brilliant            (score=84.16)\n",
      "goal                 -> brilliant goal       (score=86.85)\n",
      "goal .               -> goal                 (score=85.34)\n",
      ".                    -> goal .               (score=76.77)\n",
      ". the                -> .                    (score=76.61)\n",
      "the                  -> . the                (score=85.41)\n",
      "the a                -> the                  (score=78.52)\n",
      "a                    -> the a                (score=58.41)\n",
      "a ##rgent            -> a                    (score=62.93)\n",
      "##rgent              -> a                    (score=76.25)\n",
      "##rgent ##ine        -> ##rgent              (score=84.38)\n",
      "##ine                -> ##rgent ##ine        (score=89.21)\n",
      "##ine forward        -> ##ine                (score=90.75)\n",
      "forward              -> ##ine forward        (score=93.76)\n",
      "forward celebrated   -> forward              (score=104.04)\n",
      "celebrated           -> forward celebrated   (score=119.29)\n",
      "celebrated with      -> celebrated           (score=116.00)\n",
      "with                 -> celebrated with      (score=95.83)\n",
      "with his             -> celebrated           (score=101.23)\n",
      "his                  -> with his             (score=115.28)\n",
      "his teammates        -> his                  (score=119.47)\n",
      "teammates            -> his teammates        (score=110.54)\n",
      "teammates .          -> teammates            (score=93.02)\n",
      ".                    -> teammates .          (score=75.39)\n",
      ". he                 -> his                  (score=79.11)\n",
      "he                   -> his                  (score=88.03)\n",
      "he is                -> his                  (score=88.93)\n",
      "is                   -> he is                (score=93.62)\n",
      "is considered        -> is                   (score=94.79)\n",
      "considered           -> is considered        (score=91.75)\n",
      "considered one       -> considered           (score=89.39)\n",
      "one                  -> considered one       (score=90.05)\n",
      "one of               -> one                  (score=93.36)\n",
      "of                   -> one of               (score=91.08)\n",
      "of the               -> of                   (score=89.32)\n",
      "the                  -> of the               (score=86.39)\n",
      "the best             -> his                  (score=85.59)\n",
      "best                 -> his                  (score=94.75)\n",
      "best players         -> best                 (score=94.87)\n",
      "players              -> best players         (score=84.56)\n",
      "players in           -> players              (score=83.23)\n",
      "in                   -> players in           (score=86.99)\n",
      "in the               -> in                   (score=91.19)\n",
      "the                  -> in the               (score=83.28)\n",
      "the world            -> the                  (score=78.20)\n",
      "world                -> best                 (score=80.35)\n",
      "world .              -> world                (score=69.11)\n",
      ".                    -> celebrated           (score=56.17)\n",
      ". [SEP]              -> [CLS]                (score=56.34)\n",
      "[SEP]                -> [CLS]                (score=65.43)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:58.104669Z",
     "start_time": "2025-12-04T09:10:58.098884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clusters_text\n",
    "clusters_text = []\n",
    "for cluster in clusters:\n",
    "    clusters_text.append([\" \".join(token_list[start:end+1]) for start, end in cluster])\n",
    "print(\"\\n[Final Output] Candidate clusters (resolved mentions):\", clusters_text)\n",
    "\n",
    "# Only clusters with â‰¥2 mentions\n",
    "relevant_clusters = [c for c in clusters_text if len(c) > 1]\n",
    "\n",
    "print(\"\\n[Relevant Entity Clusters]:\")\n",
    "for c in relevant_clusters:\n",
    "    print(c)\n"
   ],
   "id": "ee9b1b69c3ca3fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Output] Candidate clusters (resolved mentions): [['[CLS]', '[CLS] lion', 'lion', 'lion ##el', '##el', '##el mess', 'mess', 'mess ##i', '##i', '##i scored', 'scored', 'scored a', 'a', 'a brilliant', 'brilliant', 'brilliant goal', 'goal', 'goal .', '.', '. the', 'the', 'the a', 'a', 'a ##rgent', '##rgent', '##rgent ##ine', '##ine', '##ine forward', 'forward', 'forward celebrated', 'celebrated', 'celebrated with', 'with', 'with his', 'his', 'his teammates', 'teammates', 'teammates .', '.', '. he', 'he', 'he is', 'is', 'is considered', 'considered', 'considered one', 'one', 'one of', 'of', 'of the', 'the', 'the best', 'best', 'best players', 'players', 'players in', 'in', 'in the', 'the', 'the world', 'world', 'world .', '.', '. [SEP]', '[SEP]']]\n",
      "\n",
      "[Relevant Entity Clusters]:\n",
      "['[CLS]', '[CLS] lion', 'lion', 'lion ##el', '##el', '##el mess', 'mess', 'mess ##i', '##i', '##i scored', 'scored', 'scored a', 'a', 'a brilliant', 'brilliant', 'brilliant goal', 'goal', 'goal .', '.', '. the', 'the', 'the a', 'a', 'a ##rgent', '##rgent', '##rgent ##ine', '##ine', '##ine forward', 'forward', 'forward celebrated', 'celebrated', 'celebrated with', 'with', 'with his', 'his', 'his teammates', 'teammates', 'teammates .', '.', '. he', 'he', 'he is', 'is', 'is considered', 'considered', 'considered one', 'one', 'one of', 'of', 'of the', 'the', 'the best', 'best', 'best players', 'players', 'players in', 'in', 'in the', 'the', 'the world', 'world', 'world .', '.', '. [SEP]', '[SEP]']\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
