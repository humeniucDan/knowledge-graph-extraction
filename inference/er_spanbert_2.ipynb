{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:31.596242Z",
     "start_time": "2025-12-04T21:03:29.242318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ],
   "id": "3429acea57c9bdca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/Work/utcn/an4/sem1/pso/proj/knowledge-graph-extraction/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:31.603497Z",
     "start_time": "2025-12-04T21:03:31.601549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================\n",
    "# 0. LOCAL PROJECT CACHE\n",
    "# ============================================================\n",
    "\n",
    "project_cache_dir = \"./hf_cache\"\n",
    "os.makedirs(project_cache_dir, exist_ok=True)\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = project_cache_dir\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = project_cache_dir"
   ],
   "id": "ac500b54b85d44d5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.406221Z",
     "start_time": "2025-12-04T21:03:31.653720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================\n",
    "# 1. LOAD MODEL + TOKENIZER (SpanBERT-base)\n",
    "# ============================================================\n",
    "\n",
    "model_name = \"SpanBERT/spanbert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=project_cache_dir\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=project_cache_dir\n",
    ")"
   ],
   "id": "4e004c6375ce8767",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.648791Z",
     "start_time": "2025-12-04T21:03:33.458632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n[INFO] Model + tokenizer loaded.\\n\")"
   ],
   "id": "79006e3d7b5cf3b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model + tokenizer loaded.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.662818Z",
     "start_time": "2025-12-04T21:03:33.657493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================\n",
    "# 2. INPUT TEXT\n",
    "# ============================================================\n",
    "\n",
    "text = \"Lionel Messi scored a brilliant goal. The Argentine forward celebrated with his teammates. He is considered one of the best players in the world.\"\n",
    "\n",
    "# Tokenize\n",
    "enc = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "input_ids = enc[\"input_ids\"].to(device)\n",
    "attention_mask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().tolist())\n",
    "\n",
    "print(\"[TOKENS]:\")\n",
    "print(tokens, \"\\n\")\n"
   ],
   "id": "2269ad9ff607abd7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKENS]:\n",
      "['[CLS]', 'lion', '##el', 'mess', '##i', 'scored', 'a', 'brilliant', 'goal', '.', 'the', 'a', '##rgent', '##ine', 'forward', 'celebrated', 'with', 'his', 'teammates', '.', 'he', 'is', 'considered', 'one', 'of', 'the', 'best', 'players', 'in', 'the', 'world', '.', '[SEP]'] \n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.791460Z",
     "start_time": "2025-12-04T21:03:33.714799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    hidden_states = outputs.last_hidden_state.squeeze(0)   # [seq_len, hidden]\n",
    "    hidden_states = hidden_states.cpu()\n"
   ],
   "id": "f24fdd3b3ef516f7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.798897Z",
     "start_time": "2025-12-04T21:03:33.796436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 3. CREATE CANDIDATE SPANS  (single tokens only for demo)\n",
    "# ============================================================\n",
    "\n",
    "spans = []\n",
    "span_embeddings = []\n",
    "\n",
    "for i in range(1, len(tokens)-1):  # skip CLS / SEP\n",
    "    span = [tokens[i]]\n",
    "    spans.append(span)\n",
    "    span_embeddings.append(hidden_states[i])\n",
    "\n",
    "print(\"[RAW SPANS]:\")\n",
    "for s in spans:\n",
    "    print(s)\n",
    "print(\"\\n\")\n"
   ],
   "id": "978f33096ff177d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAW SPANS]:\n",
      "['lion']\n",
      "['##el']\n",
      "['mess']\n",
      "['##i']\n",
      "['scored']\n",
      "['a']\n",
      "['brilliant']\n",
      "['goal']\n",
      "['.']\n",
      "['the']\n",
      "['a']\n",
      "['##rgent']\n",
      "['##ine']\n",
      "['forward']\n",
      "['celebrated']\n",
      "['with']\n",
      "['his']\n",
      "['teammates']\n",
      "['.']\n",
      "['he']\n",
      "['is']\n",
      "['considered']\n",
      "['one']\n",
      "['of']\n",
      "['the']\n",
      "['best']\n",
      "['players']\n",
      "['in']\n",
      "['the']\n",
      "['world']\n",
      "['.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.857928Z",
     "start_time": "2025-12-04T21:03:33.849681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 4. BUILD NAIVE CLUSTERS BASED ON SIMILARITY\n",
    "# ============================================================\n",
    "\n",
    "clusters_text = []\n",
    "clusters_embeds = []\n",
    "\n",
    "for i, span_vec in enumerate(span_embeddings):\n",
    "    if not clusters_text:\n",
    "        clusters_text.append([spans[i][0]])\n",
    "        clusters_embeds.append([span_vec])\n",
    "        continue\n",
    "\n",
    "    best_score = -1e9\n",
    "    best_cluster = None\n",
    "\n",
    "    for c_idx, c in enumerate(clusters_embeds):\n",
    "        c_centroid = torch.stack(c).mean(dim=0)\n",
    "        score = torch.dot(span_vec, c_centroid).item()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_cluster = c_idx\n",
    "\n",
    "    clusters_text[best_cluster].append(spans[i][0])\n",
    "    clusters_embeds[best_cluster].append(span_vec)\n",
    "\n",
    "print(\"============================================\")\n",
    "print(\" RAW CLUSTERS (UNMERGED)\")\n",
    "print(\"============================================\")\n",
    "for idx, cluster in enumerate(clusters_text):\n",
    "    print(f\"Cluster {idx+1}: {cluster}\")\n",
    "print(\"\\n\")\n"
   ],
   "id": "8a2c0909f062bd13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      " RAW CLUSTERS (UNMERGED)\n",
      "============================================\n",
      "Cluster 1: ['lion', '##el', 'mess', '##i', 'scored', 'a', 'brilliant', 'goal', '.', 'the', 'a', '##rgent', '##ine', 'forward', 'celebrated', 'with', 'his', 'teammates', '.', 'he', 'is', 'considered', 'one', 'of', 'the', 'best', 'players', 'in', 'the', 'world', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.909380Z",
     "start_time": "2025-12-04T21:03:33.905269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 5. MERGE SUBWORDS (##tokens)\n",
    "# ============================================================\n",
    "\n",
    "def merge_subwords(tokens):\n",
    "    out = []\n",
    "    current = \"\"\n",
    "    for tok in tokens:\n",
    "        if tok.startswith(\"##\"):\n",
    "            current += tok[2:]\n",
    "        else:\n",
    "            if current:\n",
    "                out.append(current)\n",
    "            current = tok\n",
    "    if current:\n",
    "        out.append(current)\n",
    "    return out\n",
    "\n",
    "clean_clusters = []\n",
    "\n",
    "for cluster in clusters_text:\n",
    "    merged = merge_subwords(cluster)\n",
    "    if len(merged) >= 1:\n",
    "        clean_clusters.append(merged)\n"
   ],
   "id": "3ff2d739fe20483b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T21:03:33.957242Z",
     "start_time": "2025-12-04T21:03:33.954633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 6. DISPLAY CLEAN CLUSTERS\n",
    "# ============================================================\n",
    "\n",
    "print(\"============================================\")\n",
    "print(\" CLEANED & MERGED CLUSTERS\")\n",
    "print(\"============================================\")\n",
    "\n",
    "for idx, cluster in enumerate(clean_clusters):\n",
    "    # choose canonical name:\n",
    "    canonical = next((w for w in cluster if w[0].isupper()), cluster[0])\n",
    "    print(f\"Cluster {idx+1} (canonical: {canonical}): {cluster}\")\n",
    "\n",
    "print(\"\\n[FINISHED]\\n\")\n"
   ],
   "id": "8cbce36ac8631f61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      " CLEANED & MERGED CLUSTERS\n",
      "============================================\n",
      "Cluster 1 (canonical: lionel): ['lionel', 'messi', 'scored', 'a', 'brilliant', 'goal', '.', 'the', 'argentine', 'forward', 'celebrated', 'with', 'his', 'teammates', '.', 'he', 'is', 'considered', 'one', 'of', 'the', 'best', 'players', 'in', 'the', 'world', '.']\n",
      "\n",
      "[FINISHED]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
